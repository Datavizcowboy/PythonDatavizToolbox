{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks retrieval on the Satellite Observations Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this final step we develop a model to estimate soil moisture using neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries we need are imported first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "import xarray as xr\n",
    "from scipy.interpolate import griddata\n",
    "from scipy import interpolate\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.optim import SGD\n",
    "\n",
    "\n",
    "# from torch.optim import RMSprop\n",
    "# from torch.utils.data import TensorDataset\n",
    "# from torchmetrics import (MeanAbsoluteError, R2Score)\n",
    "# # from torchinfo import summary\n",
    "# from torchvision.io import read_image\n",
    "# from pytorch_lightning import Trainer\n",
    "# from pytorch_lightning.loggers import CSVLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data used in this exercise is stored in the DATA folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "thefile = '../../../DATA/TPdata_199301'\n",
    "data = pd.read_csv(thefile, sep='\\t', header=None)\n",
    "data.columns = [\"cellNr\", \"latitude\", \"longitude\", \"backscatter\",\"emissivity_v\",\"emissivity_h\",\"ts_amplitude\",\"ndvi\",\"lmd_soilWetness\"]\n",
    "data = data.replace('   NaN',pd.NA)\n",
    "data['backscatter'] = pd.to_numeric(data['backscatter'])\n",
    "data['emissivity_v'] = pd.to_numeric(data['emissivity_v'])\n",
    "data['emissivity_h'] = pd.to_numeric(data['emissivity_h'])\n",
    "data['ts_amplitude'] = pd.to_numeric(data['ts_amplitude'])\n",
    "data['ndvi'] = pd.to_numeric(data['ndvi'])\n",
    "data['lmd_soilWetness'] = pd.to_numeric(data['lmd_soilWetness'])\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "back = data['backscatter'].values[0:thres]\n",
    "lats = data['latitude'].values[0:thres]\n",
    "lons = data['longitude'].values[0:thres]\n",
    "emissivity_v = data['emissivity_v'].values[0:thres]\n",
    "emissivity_h = data['emissivity_h'].values[0:thres]\n",
    "ts_amplitude = data['ts_amplitude'].values[0:thres]\n",
    "ndvi = data['ndvi'].values[0:thres]\n",
    "lmd_soilWetness = data['lmd_soilWetness'].values[0:thres]\n",
    "Yi = np.linspace(np.min(lats.data),float(np.max(lats.data)),180)\n",
    "Xi = np.linspace(np.min(lons.data),float(np.max(lons.data)),360)\n",
    "X, Y = np.meshgrid(Xi,Yi)\n",
    "points = list(zip(lons, lats))\n",
    "back_gridded = griddata(points, back, (X, Y), method='nearest')\n",
    "emissivity_v_gridded = griddata(points, emissivity_v, (X, Y), method='nearest')\n",
    "emissivity_h_gridded = griddata(points, emissivity_h, (X, Y), method='nearest')\n",
    "ts_amplitude_gridded = griddata(points, ts_amplitude, (X, Y), method='nearest')\n",
    "ndvi_gridded = griddata(points, ndvi, (X, Y), method='nearest')\n",
    "lmd_soilWetness_gridded = griddata(points, lmd_soilWetness, (X, Y), method='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(5,100)  \n",
    "        self.fc2 = nn.Linear(100,1)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))  \n",
    "        x = self.fc2(x)               \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "alles = np.stack((back,emissivity_v,emissivity_h,ts_amplitude,ndvi),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(alles).to(torch.float32)\n",
    "y_train = torch.tensor(lmd_soilWetness).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN()  \n",
    "criterion = nn.MSELoss()  \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([20000])) that is different to the input size (torch.Size([20000, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 26426.5234\n",
      "Epoch [20/100], Loss: 304.7427\n",
      "Epoch [30/100], Loss: 3.5792\n",
      "Epoch [40/100], Loss: 0.1070\n",
      "Epoch [50/100], Loss: 0.0670\n",
      "Epoch [60/100], Loss: 0.0665\n",
      "Epoch [70/100], Loss: 0.0665\n",
      "Epoch [80/100], Loss: 0.0665\n",
      "Epoch [90/100], Loss: 0.0665\n",
      "Epoch [100/100], Loss: 0.0665\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):  \n",
    "    model.train() \n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)  \n",
    "    \n",
    "    # Backward pass and optimize\n",
    "    optimizer.zero_grad()  \n",
    "    loss.backward()  \n",
    "    optimizer.step()  \n",
    "\n",
    "    if (epoch + 1) % 10 == 0:  \n",
    "        print(f'Epoch [{epoch + 1}/100], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
